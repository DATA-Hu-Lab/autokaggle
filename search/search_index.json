{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Auto-Kaggle is an open source software library for automated kaggle competition. It is developed by DATA Lab at Texas A&M University and community contributors. Installation To install the package, please use the pip installation as follows: pip install autokaggle Note: currently, Auto-Kaggle is only compatible with: Python 3.6 . Example Here is a short example of using the package. import autokaggle as ak clf = ak.TabularClassifier(verbose=True) clf.fit(x_train, y_train, time_limit=12 * 60 * 60, data_info=datainfo) DISCLAIMER Please note that this is a pre-release version of the Auto-Kaggle which is still undergoing final testing before its official release. The website, its software and all content found on it are provided on an \u201cas is\u201d and \u201cas available\u201d basis. Auto-Kaggle does not give any warranties, whether express or implied, as to the suitability or usability of the website, its software or any of its content. Auto-Kaggle will not be liable for any loss, whether such loss is direct, indirect, special or consequential, suffered by any party as a result of their use of the libraries or content. Any usage of the libraries is done at the user\u2019s own risk and the user will be solely responsible for any damage to any computer system or loss of data that results from such activities. Should you encounter any bugs, glitches, lack of functionality or other problems on the website, please let us know immediately so we can rectify these accordingly. Your help in this regard is greatly appreciated. Acknowledgements The authors gratefully acknowledge the D3M program of the Defense Advanced Research Projects Agency (DARPA) administered through AFRL contract FA8750-17-2-0116; the Texas A&M College of Engineering, and Texas A&M.","title":"Home"},{"location":"#installation","text":"To install the package, please use the pip installation as follows: pip install autokaggle Note: currently, Auto-Kaggle is only compatible with: Python 3.6 .","title":"Installation"},{"location":"#example","text":"Here is a short example of using the package. import autokaggle as ak clf = ak.TabularClassifier(verbose=True) clf.fit(x_train, y_train, time_limit=12 * 60 * 60, data_info=datainfo)","title":"Example"},{"location":"#disclaimer","text":"Please note that this is a pre-release version of the Auto-Kaggle which is still undergoing final testing before its official release. The website, its software and all content found on it are provided on an \u201cas is\u201d and \u201cas available\u201d basis. Auto-Kaggle does not give any warranties, whether express or implied, as to the suitability or usability of the website, its software or any of its content. Auto-Kaggle will not be liable for any loss, whether such loss is direct, indirect, special or consequential, suffered by any party as a result of their use of the libraries or content. Any usage of the libraries is done at the user\u2019s own risk and the user will be solely responsible for any damage to any computer system or loss of data that results from such activities. Should you encounter any bugs, glitches, lack of functionality or other problems on the website, please let us know immediately so we can rectify these accordingly. Your help in this regard is greatly appreciated.","title":"DISCLAIMER"},{"location":"#acknowledgements","text":"The authors gratefully acknowledge the D3M program of the Defense Advanced Research Projects Agency (DARPA) administered through AFRL contract FA8750-17-2-0116; the Texas A&M College of Engineering, and Texas A&M.","title":"Acknowledgements"},{"location":"about/","text":"About This package is developed by DATA LAB at Texas A&M University and community contributors.","title":"About"},{"location":"about/#about","text":"This package is developed by DATA LAB at Texas A&M University and community contributors.","title":"About"},{"location":"start/","text":"Getting Started Installation The installation of Auto-Kaggle is the same as other python packages. Note: currently, Auto-Kaggle is only compatible with: Python 3.6 . Latest Stable Version ( pip installation): You can run the following pip installation command in your terminal to install the latest stable version. pip install autokaggle Bleeding Edge Version (manual installation): If you want to install the latest development version. You need to download the code from the GitHub repo and run the following commands in the project directory. pip install -r requirements.txt python setup.py install A Simple Example We show an example of binary classification using the randomly generated data. Data with numpy array (.npy) format. [source] If the train/test data are already formatted into numpy arrays, you can import numpy as np from autokeras import TabularClassifier if __name__ == '__main__': ntime, nnum, ncat = 4, 10, 8 nsample = 1000 x_num = np.random.random([nsample, nnum]) x_time = np.random.random([nsample, ntime]) x_cat = np.random.randint(0, 10, [nsample, ncat]) x_all = np.concatenate([x_num, x_time, x_cat], axis=1) x_train = x_all[:int(nsample * 0.8), :] x_test = x_all[int(nsample * 0.8):, :] y_all = np.random.randint(0, 2, nsample) y_train = y_all[:int(nsample * 0.8)] y_test = y_all[int(nsample * 0.8):] clf = TabularClassifier() datainfo = np.array(['TIME'] * ntime + ['NUM'] * nnum + ['CAT'] * ncat) clf.fit(x_train, y_train, time_limit=12 * 60 * 60, data_info=datainfo) AUC = clf.evaluate(x_test, y_test) print(AUC) In the example above, the train/test data are already formatted into numpy arrays.","title":"Getting Started"},{"location":"start/#getting-started","text":"","title":"Getting Started"},{"location":"start/#installation","text":"The installation of Auto-Kaggle is the same as other python packages. Note: currently, Auto-Kaggle is only compatible with: Python 3.6 .","title":"Installation"},{"location":"start/#latest-stable-version-pip-installation","text":"You can run the following pip installation command in your terminal to install the latest stable version. pip install autokaggle","title":"Latest Stable Version (pip installation):"},{"location":"start/#bleeding-edge-version-manual-installation","text":"If you want to install the latest development version. You need to download the code from the GitHub repo and run the following commands in the project directory. pip install -r requirements.txt python setup.py install","title":"Bleeding Edge Version (manual installation):"},{"location":"start/#a-simple-example","text":"We show an example of binary classification using the randomly generated data.","title":"A Simple Example"},{"location":"start/#data-with-numpy-array-npy-format","text":"[source] If the train/test data are already formatted into numpy arrays, you can import numpy as np from autokeras import TabularClassifier if __name__ == '__main__': ntime, nnum, ncat = 4, 10, 8 nsample = 1000 x_num = np.random.random([nsample, nnum]) x_time = np.random.random([nsample, ntime]) x_cat = np.random.randint(0, 10, [nsample, ncat]) x_all = np.concatenate([x_num, x_time, x_cat], axis=1) x_train = x_all[:int(nsample * 0.8), :] x_test = x_all[int(nsample * 0.8):, :] y_all = np.random.randint(0, 2, nsample) y_train = y_all[:int(nsample * 0.8)] y_test = y_all[int(nsample * 0.8):] clf = TabularClassifier() datainfo = np.array(['TIME'] * ntime + ['NUM'] * nnum + ['CAT'] * ncat) clf.fit(x_train, y_train, time_limit=12 * 60 * 60, data_info=datainfo) AUC = clf.evaluate(x_test, y_test) print(AUC) In the example above, the train/test data are already formatted into numpy arrays.","title":"Data with numpy array (.npy) format."},{"location":"temp/contribute/","text":"Contributing Guide Contributions are welcome, and greatly appreciated! Every little bit helps, and credit will always be given. We recommend you to check our Developer Tools Guide to make the development process easier and standard. Notably, you can follow the tag of call for contributors in the issues. Those issues are designed for the external contributors to solve. The pull requests solving these issues are most likely to be merged. There are many ways to contribute to Auto-Keras, including submit feedback, fix bugs, implement features, and write documentation. The guide for each type of contribution is as follows. Submit Feedback The feedback should be submitted by creating an issue at GitHub issues . Select the related template (bug report, feature request, or custom) and add the corresponding labels. Fix Bugs: You may look through the GitHub issues for bugs. Anything tagged with \"bug report\" is open to whoever wants to implement it. Please follow the Pull Request Guide to submit your pull request. Please also read Code Style Guide , and Documentation Guide to ensure your merge request meet our requirements. Implement Features You may look through the GitHub issues for feature requests. Anything tagged with \"feature request\" is open to whoever wants to implement it. Please follow the Pull Request Guide to submit your pull request. Please also read Code Style Guide , Documentation Guide , and Testing Guide to ensure your merge request meet our requirements. Write Documentation The documentation of Auto-Keras is either directly written into the Markdown files in mkdocs directory , or automatically extracted from the docstrings by executing the autogen.py . In the first situation, you only need to change the markdown file. In the second situation, you need to change the docstrings and execute autogen.py to update the Markdown files. Please follow the Pull Request Guide to submit your pull request. Please also read Documentation Guide to ensure your merge request meet our requirements. Pull Request Guide Before you submit a pull request, check that it meets these guidelines: Fork the repository. Create a new branch from the master branch. Give your new branch a meaningful name. Pull request from your new branch to the master branch of the original autokaggle repo. Give your pull request a meaningful name. Include \"resolves #issue_number\" in the description of the pull request and briefly describe your contribution. Submit the pull request from the first day of your development (after your first commit) and prefix the title of the pull request with [WIP] . When the contribution is complete, make sure the pull request passed the CI tests. Change the [WIP] to [MRG] . Set the reviewer to @jhfjhfj1 . For the case of bug fixes, add new test cases which would fail before your bug fix. If you are a collaborator of the autokaggle repo, you don't need to fork the repository. Just create a new branch directly. You also need to change the assignee to the reviewer when request for code review. The reviewer will change the assignee back to you when finished the review. The assignee always means who should push the progress of the pull request now. Code Style Guide This project tries to closely follow the official Python Style Guide detailed in PEP8 . The docstrings follow the Google Python Style Guide . Please follow these style guide closely, especially for the docstrings, which would be extracted automatically to generate the documentation. Documentation Guide: The documentation should be provided in two ways, docstring, tutorial, and readme file. We prefer the documentation to be as complete as possible. Docstring All the methods and classes may directly be called by the user need to be documented with docstrings. The docstrings should contain all the fields required by the Google Python Style Guide . Tutorial You only need to add tutorials to your code if you are contributing or updating a new task module, e.g. TextClassifier, VideoClassifier, or a new function could be directly called by the user. You can modify mkdocs/docs/start.md to add your tutorial. The code example of your new task module should be added to the examples directory. Readme File You only need to add tutorials to your code if you are contributing or updating a new task module, e.g. TextClassifier, VideoClassifier. The readme file should be named as README.md . It should be written in Markdown. The content should contain your name, affiliation, and any reference to the method you use. Testing Guide Pytest is used to write the unit tests of Auto-Keras. You should test your code by writing unit testing code in tests directory. The testing file name should be the .py file with a prefix of test_ in the corresponding directory, e.g., the name should be test_layers.py if the code of which is to test layer.py . The tests should be run in the root directory of the project by executing the cov.sh file. It would output the coverage information into a directory named htmlcov . Please make sure the code coverage percentage does not decrease after your contribution, otherwise, the code will not be merged. Developer Tools Guide We highly recommend you to use Pycharm and virtualenvwrapper . Pycharm Pycharm is the best IDE for large project development in Python. We recommend you inspect the code before you pull request to fix any error and warning suggested by the inspection. Virtualenvwrapper Virtualenvwrapper is a tool to build separated Python environment for each project. In this way, you can install a different version of Tensorflow, Pytorch, or any other package for each project. We recommend you to create a virtualenv for autokaggle development with virtualenvwrapper, and only install the packages required by autokaggle with the corresponding version. The virtualenv should be created based on Python 3.6 interpreter. Use pycharm to select the virtualenv as interpreter . Reusable Code Guide You may checkout this code review video to get familiar with the code structure. Other than the base classes you have to extend, there are some other classes you can extend. Main Contributor List We really appreciate all the contributions. To show our appreciation to those who contributed most, we would like to maintain a list of main contributors. To be in the list, you need to meet the following requirments. 1. Be on campus of Texas A&M University. 2. Constantly present in our meetings. 3. Constantly contribute code to our repository. 4. Keep the above for over 6 months.","title":"Contributing Guide"},{"location":"temp/contribute/#contributing-guide","text":"Contributions are welcome, and greatly appreciated! Every little bit helps, and credit will always be given. We recommend you to check our Developer Tools Guide to make the development process easier and standard. Notably, you can follow the tag of call for contributors in the issues. Those issues are designed for the external contributors to solve. The pull requests solving these issues are most likely to be merged. There are many ways to contribute to Auto-Keras, including submit feedback, fix bugs, implement features, and write documentation. The guide for each type of contribution is as follows.","title":"Contributing Guide"},{"location":"temp/contribute/#submit-feedback","text":"The feedback should be submitted by creating an issue at GitHub issues . Select the related template (bug report, feature request, or custom) and add the corresponding labels.","title":"Submit Feedback"},{"location":"temp/contribute/#fix-bugs","text":"You may look through the GitHub issues for bugs. Anything tagged with \"bug report\" is open to whoever wants to implement it. Please follow the Pull Request Guide to submit your pull request. Please also read Code Style Guide , and Documentation Guide to ensure your merge request meet our requirements.","title":"Fix Bugs:"},{"location":"temp/contribute/#implement-features","text":"You may look through the GitHub issues for feature requests. Anything tagged with \"feature request\" is open to whoever wants to implement it. Please follow the Pull Request Guide to submit your pull request. Please also read Code Style Guide , Documentation Guide , and Testing Guide to ensure your merge request meet our requirements.","title":"Implement Features"},{"location":"temp/contribute/#write-documentation","text":"The documentation of Auto-Keras is either directly written into the Markdown files in mkdocs directory , or automatically extracted from the docstrings by executing the autogen.py . In the first situation, you only need to change the markdown file. In the second situation, you need to change the docstrings and execute autogen.py to update the Markdown files. Please follow the Pull Request Guide to submit your pull request. Please also read Documentation Guide to ensure your merge request meet our requirements.","title":"Write Documentation"},{"location":"temp/contribute/#pull-request-guide","text":"Before you submit a pull request, check that it meets these guidelines: Fork the repository. Create a new branch from the master branch. Give your new branch a meaningful name. Pull request from your new branch to the master branch of the original autokaggle repo. Give your pull request a meaningful name. Include \"resolves #issue_number\" in the description of the pull request and briefly describe your contribution. Submit the pull request from the first day of your development (after your first commit) and prefix the title of the pull request with [WIP] . When the contribution is complete, make sure the pull request passed the CI tests. Change the [WIP] to [MRG] . Set the reviewer to @jhfjhfj1 . For the case of bug fixes, add new test cases which would fail before your bug fix. If you are a collaborator of the autokaggle repo, you don't need to fork the repository. Just create a new branch directly. You also need to change the assignee to the reviewer when request for code review. The reviewer will change the assignee back to you when finished the review. The assignee always means who should push the progress of the pull request now.","title":"Pull Request Guide"},{"location":"temp/contribute/#code-style-guide","text":"This project tries to closely follow the official Python Style Guide detailed in PEP8 . The docstrings follow the Google Python Style Guide . Please follow these style guide closely, especially for the docstrings, which would be extracted automatically to generate the documentation.","title":"Code Style Guide"},{"location":"temp/contribute/#documentation-guide","text":"The documentation should be provided in two ways, docstring, tutorial, and readme file. We prefer the documentation to be as complete as possible.","title":"Documentation Guide:"},{"location":"temp/contribute/#docstring","text":"All the methods and classes may directly be called by the user need to be documented with docstrings. The docstrings should contain all the fields required by the Google Python Style Guide .","title":"Docstring"},{"location":"temp/contribute/#tutorial","text":"You only need to add tutorials to your code if you are contributing or updating a new task module, e.g. TextClassifier, VideoClassifier, or a new function could be directly called by the user. You can modify mkdocs/docs/start.md to add your tutorial. The code example of your new task module should be added to the examples directory.","title":"Tutorial"},{"location":"temp/contribute/#readme-file","text":"You only need to add tutorials to your code if you are contributing or updating a new task module, e.g. TextClassifier, VideoClassifier. The readme file should be named as README.md . It should be written in Markdown. The content should contain your name, affiliation, and any reference to the method you use.","title":"Readme File"},{"location":"temp/contribute/#testing-guide","text":"Pytest is used to write the unit tests of Auto-Keras. You should test your code by writing unit testing code in tests directory. The testing file name should be the .py file with a prefix of test_ in the corresponding directory, e.g., the name should be test_layers.py if the code of which is to test layer.py . The tests should be run in the root directory of the project by executing the cov.sh file. It would output the coverage information into a directory named htmlcov . Please make sure the code coverage percentage does not decrease after your contribution, otherwise, the code will not be merged.","title":"Testing Guide"},{"location":"temp/contribute/#developer-tools-guide","text":"We highly recommend you to use Pycharm and virtualenvwrapper .","title":"Developer Tools Guide"},{"location":"temp/contribute/#pycharm","text":"Pycharm is the best IDE for large project development in Python. We recommend you inspect the code before you pull request to fix any error and warning suggested by the inspection.","title":"Pycharm"},{"location":"temp/contribute/#virtualenvwrapper","text":"Virtualenvwrapper is a tool to build separated Python environment for each project. In this way, you can install a different version of Tensorflow, Pytorch, or any other package for each project. We recommend you to create a virtualenv for autokaggle development with virtualenvwrapper, and only install the packages required by autokaggle with the corresponding version. The virtualenv should be created based on Python 3.6 interpreter. Use pycharm to select the virtualenv as interpreter .","title":"Virtualenvwrapper"},{"location":"temp/contribute/#reusable-code-guide","text":"You may checkout this code review video to get familiar with the code structure. Other than the base classes you have to extend, there are some other classes you can extend.","title":"Reusable Code Guide"},{"location":"temp/contribute/#main-contributor-list","text":"We really appreciate all the contributions. To show our appreciation to those who contributed most, we would like to maintain a list of main contributors. To be in the list, you need to meet the following requirments. 1. Be on campus of Texas A&M University. 2. Constantly present in our meetings. 3. Constantly contribute code to our repository. 4. Keep the above for over 6 months.","title":"Main Contributor List"},{"location":"temp/tabular_preprocessor/","text":"TabularPreprocessor init Initialization function for tabular preprocessor. fit This function should train the model parameters. Args raw_x : a numpy.ndarray instance containing the training data. y : training label vector. time_limit : remaining time budget. data_info : meta-features of the dataset, which is an numpy.ndarray describing the feature type of each column in raw_x. The feature type include encode This function should train the model parameters. Args raw_x : a numpy.ndarray instance containing the training/testing data. time_limit : remaining time budget. inputs X and y are numpy arrays. extract_data_info This function extracts the data info automatically based on the type of each feature in raw_x. Args raw_x : a numpy.ndarray instance containing the training data.","title":"tabular_preprocessor"},{"location":"temp/tabular_preprocessor/#tabularpreprocessor","text":"","title":"TabularPreprocessor"},{"location":"temp/tabular_preprocessor/#init","text":"Initialization function for tabular preprocessor.","title":"init"},{"location":"temp/tabular_preprocessor/#fit","text":"This function should train the model parameters.","title":"fit"},{"location":"temp/tabular_preprocessor/#args","text":"raw_x : a numpy.ndarray instance containing the training data. y : training label vector. time_limit : remaining time budget. data_info : meta-features of the dataset, which is an numpy.ndarray describing the feature type of each column in raw_x. The feature type include","title":"Args"},{"location":"temp/tabular_preprocessor/#encode","text":"This function should train the model parameters.","title":"encode"},{"location":"temp/tabular_preprocessor/#args_1","text":"raw_x : a numpy.ndarray instance containing the training/testing data. time_limit : remaining time budget. inputs X and y are numpy arrays.","title":"Args"},{"location":"temp/tabular_preprocessor/#extract_data_info","text":"This function extracts the data info automatically based on the type of each feature in raw_x.","title":"extract_data_info"},{"location":"temp/tabular_preprocessor/#args_2","text":"raw_x : a numpy.ndarray instance containing the training data.","title":"Args"},{"location":"temp/tabular_supervised/","text":"TabularSupervised init Initialization function for tabular supervised learner. fit This function should train the model parameters. Args x : A numpy.ndarray instance containing the training data. y : training label vector. time_limit : remaining time budget. data_info : meta-features of the dataset, which is an numpy.ndarray describing the feature type of each column in raw_x. The feature type include predict This function should provide predictions of labels on (test) data. The function predict eventually casdn return probabilities or continuous values. TabularRegressor TabularRegressor class. It is used for tabular data regression with lightgbm regressor. TabularClassifier TabularClassifier class. It is used for tabular data classification with lightgbm classifier.","title":"tabular_supervised"},{"location":"temp/tabular_supervised/#tabularsupervised","text":"","title":"TabularSupervised"},{"location":"temp/tabular_supervised/#init","text":"Initialization function for tabular supervised learner.","title":"init"},{"location":"temp/tabular_supervised/#fit","text":"This function should train the model parameters.","title":"fit"},{"location":"temp/tabular_supervised/#args","text":"x : A numpy.ndarray instance containing the training data. y : training label vector. time_limit : remaining time budget. data_info : meta-features of the dataset, which is an numpy.ndarray describing the feature type of each column in raw_x. The feature type include","title":"Args"},{"location":"temp/tabular_supervised/#predict","text":"This function should provide predictions of labels on (test) data. The function predict eventually casdn return probabilities or continuous values.","title":"predict"},{"location":"temp/tabular_supervised/#tabularregressor","text":"TabularRegressor class. It is used for tabular data regression with lightgbm regressor.","title":"TabularRegressor"},{"location":"temp/tabular_supervised/#tabularclassifier","text":"TabularClassifier class. It is used for tabular data classification with lightgbm classifier.","title":"TabularClassifier"},{"location":"temp/utils/","text":"ensure_dir Create directory if it does not exist. rand_temp_folder_generator Create and return a temporary directory with the path name '/temp_dir_name/autokeras' (E:g:- /tmp/autokeras).","title":"utils"},{"location":"temp/utils/#ensure_dir","text":"Create directory if it does not exist.","title":"ensure_dir"},{"location":"temp/utils/#rand_temp_folder_generator","text":"Create and return a temporary directory with the path name '/temp_dir_name/autokeras' (E:g:- /tmp/autokeras).","title":"rand_temp_folder_generator"}]}